{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./combined-swell-classification-eda-train-dataset.csv')\n",
    "test_data = pd.read_csv('./combined-swell-classification-eda-test-dataset.csv')\n",
    "val_data = pd.read_csv('./combined-swell-classification-eda-validation-dataset.csv')\n",
    "\n",
    "train_X = train_data\n",
    "test_X = test_data\n",
    "val_X = val_data\n",
    "\n",
    "# train_Y, test_Y, val_Y\n",
    "train_Y = train_X[\"condition\"]\n",
    "test_Y = test_X[\"condition\"]\n",
    "val_Y = val_X[\"condition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X\n",
    "del train_X[\"NasaTLX class\"]\n",
    "del train_X[\"Condition Label\"]\n",
    "del train_X[\"NasaTLX Label\"]\n",
    "del train_X[\"condition\"]\n",
    "\n",
    "# test_X\n",
    "del test_X[\"NasaTLX class\"]\n",
    "del test_X[\"Condition Label\"]\n",
    "del test_X[\"NasaTLX Label\"]\n",
    "del test_X[\"condition\"]\n",
    "\n",
    "# val_X\n",
    "del val_X[\"NasaTLX class\"]\n",
    "del val_X[\"Condition Label\"]\n",
    "del val_X[\"NasaTLX Label\"]\n",
    "del val_X[\"condition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep going!\n"
     ]
    }
   ],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.split_feature = None\n",
    "        self.split_point = None\n",
    "        self.result = None\n",
    "        self.childs = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "        \n",
    "    def Gini_Impurity(self, data_Y):  # input label dataset of a group\n",
    "        impurity = 1\n",
    "        label_counts = Counter(data_Y)\n",
    "        for label in label_counts:\n",
    "            p_of_label = label_counts[label] / len(data_Y)\n",
    "            impurity -= p_of_label ** 2\n",
    "        return impurity\n",
    "    \n",
    "    def Information_Gain(self, unsplited_data_Y, splited_data_Y):\n",
    "        gain = Gini_Impurity(unsplited_data_Y)\n",
    "        # print(gain)\n",
    "        # print(splited_data_Y)\n",
    "        for subset in splited_data_Y:\n",
    "            # print(\"-\", Gini_Impurity(subset), \" X ( \", len(subset), \" / \", len(unsplited_data_Y), \" )\")\n",
    "            gain -= Gini_Impurity(subset) * (len(subset)/ len(unsplited_data_Y))\n",
    "        return gain\n",
    "    \n",
    "    def Split(self, data_X, data_Y, column):\n",
    "        data_X_subsets = []    # 분할 후의 data_X 그룹을 저장하는 배열\n",
    "        data_Y_subsets = []    # 분할 후의 data_Y 그룹을 저장하는 배열\n",
    "        split_point = 0.0      # 최적 분할 기준 값\n",
    "        split_point_gain = 0.0  # 최적 분할 지점에서의 Information Gain\n",
    "        '''\n",
    "        print(\"=-=- Before reset Index =-=-=-\")\n",
    "        print(\"**** data_X ****\")\n",
    "        print(data_X[column])\n",
    "        print(\"**** data_Y ****\")\n",
    "        print(data_Y)\n",
    "        '''\n",
    "        data_X = data_X.sort_values(by=column)\n",
    "        data_Y = data_Y[data_X.index]\n",
    "        data_X = data_X.reset_index(drop=True)\n",
    "        data_Y = data_Y.reset_index(drop=True)\n",
    "        '''\n",
    "        print(\"=-=- After reset Index =-=-=-\")\n",
    "        print(data_X.index)\n",
    "        print(data_X[column])\n",
    "        print(data_Y)\n",
    "\n",
    "        print(data_X[column].iloc[5], data_Y[5])\n",
    "        '''\n",
    "        for i in range(1, len(data_Y)):\n",
    "            candidate_splited_data_X = []\n",
    "            candidate_splited_data_Y = []\n",
    "            if data_Y[i-1] != data_Y[i]:\n",
    "                # print(i, data_Y[i-1], data_Y[i])\n",
    "                candidate_point = (data_X[column].iloc[i-1] + data_X[column].iloc[i]) / 2\n",
    "                candidate_splited_data_Y.append(data_Y[:i])\n",
    "                candidate_splited_data_Y.append(data_Y[i:])\n",
    "                gain = Information_Gain(data_Y, candidate_splited_data_Y)\n",
    "                if gain > split_point_gain:\n",
    "                    candidate_splited_data_X.append(data_X[:i])\n",
    "                    candidate_splited_data_X.append(data_X[i:])\n",
    "                    split_point = candidate_point\n",
    "                    split_point_gain = gain\n",
    "                    data_X_subsets = candidate_splited_data_X\n",
    "                    data_Y_subsets = candidate_splited_data_Y\n",
    "                    # print(\"== Updated :: \", split_point_gain, split_point)\n",
    "        return split_point_gain, split_point, data_X_subsets, data_Y_subsets\n",
    "    \n",
    "    def Find_Best_Split(self, data_X, data_Y):\n",
    "        # print(\"=-=-New Group=-=-\")\n",
    "        best_feature = ''    # 데이터를 분할 할 feature\n",
    "        best_gain = 0.0       # 데이터를 특정 feature로 분할했을 때 가장 높게 측정된 Information Gain\n",
    "        best_split_point = 0.0\n",
    "        for column in data_X.columns:\n",
    "            # print(\"check column :: \", column)\n",
    "            gain, split_point = Split(data_X, data_Y, column)[0:2]\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_feature = column\n",
    "                best_split_point = split_point\n",
    "        return best_feature, best_gain, best_split_point\n",
    "    \n",
    "    def fit(self, data_X, data_Y):\n",
    "        root = Node()\n",
    "\n",
    "        data_X = data_X.reset_index(drop=True)\n",
    "        data_Y = data_Y.reset_index(drop=True)\n",
    "\n",
    "        best_feature, best_gain, best_split_point = Find_Best_Split(data_X, data_Y)\n",
    "        if best_gain == 0:\n",
    "            # print(\"== No Split\")\n",
    "            root.result = data_Y[0]\n",
    "            # print(root.result)\n",
    "            return root\n",
    "        data_X_subsets, data_Y_subsets = Split(data_X, data_Y, best_feature)[2:]\n",
    "\n",
    "        # print(\"== Split :: \", best_feature, best_gain)\n",
    "\n",
    "        childs = []\n",
    "        for i in range(len(data_X_subsets)):\n",
    "            childs.append(fit(data_X_subsets[i], data_Y_subsets[i]))\n",
    "\n",
    "        root.split_feature = best_feature\n",
    "        root.split_point = best_split_point\n",
    "        root.childs = childs\n",
    "        self.root = root\n",
    "        \n",
    "    def predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.DecisionTree object at 0x000001E0EEF6FF08>\n",
      "<__main__.Node object at 0x000001E0EE8FF348>\n"
     ]
    }
   ],
   "source": [
    "newDT = DecisionTree()\n",
    "print(newDT)\n",
    "\n",
    "newDT.fit(test_X.head(100), test_Y.head(100))\n",
    "print(newDT.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
