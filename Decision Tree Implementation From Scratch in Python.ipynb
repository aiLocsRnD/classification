{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./combined-swell-classification-eda-train-dataset.csv')\n",
    "test_data = pd.read_csv('./combined-swell-classification-eda-test-dataset.csv')\n",
    "val_data = pd.read_csv('./combined-swell-classification-eda-validation-dataset.csv')\n",
    "\n",
    "train_X = train_data\n",
    "test_X = test_data\n",
    "val_X = val_data\n",
    "\n",
    "# train_Y, test_Y, val_Y\n",
    "train_Y = train_X[\"condition\"]\n",
    "test_Y = test_X[\"condition\"]\n",
    "val_Y = val_X[\"condition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X\n",
    "del train_X[\"NasaTLX class\"]\n",
    "del train_X[\"Condition Label\"]\n",
    "del train_X[\"NasaTLX Label\"]\n",
    "del train_X[\"condition\"]\n",
    "del train_X[\"subject_id\"]\n",
    "\n",
    "# test_X\n",
    "del test_X[\"NasaTLX class\"]\n",
    "del test_X[\"Condition Label\"]\n",
    "del test_X[\"NasaTLX Label\"]\n",
    "del test_X[\"condition\"]\n",
    "del test_X[\"subject_id\"]\n",
    "\n",
    "# val_X\n",
    "del val_X[\"NasaTLX class\"]\n",
    "del val_X[\"Condition Label\"]\n",
    "del val_X[\"NasaTLX Label\"]\n",
    "del val_X[\"condition\"]\n",
    "del val_X[\"subject_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.split_feature = None\n",
    "        self.split_point = None\n",
    "        self.result = None\n",
    "        self.childs = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "        \n",
    "    def DT_print(self, cur_node = None, cnt = 0):\n",
    "        if cnt == 0:\n",
    "            cur_node = self.root\n",
    "        print(' ' * cnt, \"Level \", cnt,\" :: \", cur_node.split_feature, cur_node.split_point, cur_node.result)\n",
    "        if cur_node.childs is None:\n",
    "            return\n",
    "        for child in cur_node.childs:\n",
    "            self.DT_print(child, cnt + 1)\n",
    "        \n",
    "    def Gini_Impurity(self, data_Y):  # input label dataset of a group\n",
    "        impurity = 1\n",
    "        label_counts = Counter(data_Y)\n",
    "        for label in label_counts:\n",
    "            p_of_label = label_counts[label] / len(data_Y)\n",
    "            impurity -= p_of_label ** 2\n",
    "        return impurity\n",
    "    \n",
    "    def Information_Gain(self, unsplited_data_Y, splited_data_Y):\n",
    "        gain = self.Gini_Impurity(unsplited_data_Y)\n",
    "        # print(gain)\n",
    "        # print(splited_data_Y)\n",
    "        for subset in splited_data_Y:\n",
    "            # print(\"-\", Gini_Impurity(subset), \" X ( \", len(subset), \" / \", len(unsplited_data_Y), \" )\")\n",
    "            gain -= self.Gini_Impurity(subset) * (len(subset)/ len(unsplited_data_Y))\n",
    "        return gain\n",
    "    \n",
    "    def Split(self, data_X, data_Y, column):\n",
    "        data_X_subsets = []    # 분할 후의 data_X 그룹을 저장하는 배열\n",
    "        data_Y_subsets = []    # 분할 후의 data_Y 그룹을 저장하는 배열\n",
    "        split_point = 0.0      # 최적 분할 기준 값\n",
    "        split_point_gain = 0.0  # 최적 분할 지점에서의 Information Gain\n",
    "        '''\n",
    "        print(\"=-=- Before reset Index =-=-=-\")\n",
    "        print(\"**** data_X ****\")\n",
    "        print(data_X[column])\n",
    "        print(\"**** data_Y ****\")\n",
    "        print(data_Y)\n",
    "        '''\n",
    "        data_X = data_X.sort_values(by=column)\n",
    "        data_Y = data_Y[data_X.index]\n",
    "        data_X = data_X.reset_index(drop=True)\n",
    "        data_Y = data_Y.reset_index(drop=True)\n",
    "        '''\n",
    "        print(\"=-=- After reset Index =-=-=-\")\n",
    "        print(data_X.index)\n",
    "        print(data_X[column])\n",
    "        print(data_Y)\n",
    "\n",
    "        print(data_X[column].iloc[5], data_Y[5])\n",
    "        '''\n",
    "        for i in range(1, len(data_Y)):\n",
    "            candidate_splited_data_X = []\n",
    "            candidate_splited_data_Y = []\n",
    "            if data_Y[i-1] != data_Y[i]:\n",
    "                # print(i, data_Y[i-1], data_Y[i])\n",
    "                candidate_point = (data_X[column].iloc[i-1] + data_X[column].iloc[i]) / 2\n",
    "                candidate_splited_data_Y.append(data_Y[:i])\n",
    "                candidate_splited_data_Y.append(data_Y[i:])\n",
    "                gain = self.Information_Gain(data_Y, candidate_splited_data_Y)\n",
    "                if gain > split_point_gain:\n",
    "                    candidate_splited_data_X.append(data_X[:i])\n",
    "                    candidate_splited_data_X.append(data_X[i:])\n",
    "                    split_point = candidate_point\n",
    "                    split_point_gain = gain\n",
    "                    data_X_subsets = candidate_splited_data_X\n",
    "                    data_Y_subsets = candidate_splited_data_Y\n",
    "                    # print(\"== Updated :: \", split_point_gain, split_point)\n",
    "        return split_point_gain, split_point, data_X_subsets, data_Y_subsets\n",
    "    \n",
    "    def Find_Best_Split(self, data_X, data_Y):\n",
    "        # print(\"=-=-New Group=-=-\")\n",
    "        best_feature = ''    # 데이터를 분할 할 feature\n",
    "        best_gain = 0.0       # 데이터를 특정 feature로 분할했을 때 가장 높게 측정된 Information Gain\n",
    "        best_split_point = 0.0\n",
    "        for column in data_X.columns:  # RF에서 Bagging Features 적용 필요.\n",
    "            # print(\"check column :: \", column)\n",
    "            gain, split_point = self.Split(data_X, data_Y, column)[0:2]\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_feature = column\n",
    "                best_split_point = split_point\n",
    "        return best_feature, best_gain, best_split_point\n",
    "    \n",
    "    def fit(self, data_X, data_Y, cnt=0):\n",
    "        root = Node()\n",
    "\n",
    "        data_X = data_X.reset_index(drop=True)\n",
    "        data_Y = data_Y.reset_index(drop=True)\n",
    "\n",
    "        best_feature, best_gain, best_split_point = self.Find_Best_Split(data_X, data_Y)\n",
    "        if best_gain == 0:\n",
    "            root.result = data_Y[0]\n",
    "            # print(' ' * cnt, \"== No Split \", cnt,\" :: \", root.result)\n",
    "            return root\n",
    "        data_X_subsets, data_Y_subsets = self.Split(data_X, data_Y, best_feature)[2:]\n",
    "\n",
    "        # print(' ' * cnt, \"== Split \", cnt,\" :: \", best_feature, best_gain)\n",
    "        childs = []\n",
    "        for i in range(len(data_X_subsets)):\n",
    "            childs.append(self.fit(data_X_subsets[i], data_Y_subsets[i], cnt+1))\n",
    "\n",
    "        root.split_feature = best_feature\n",
    "        root.split_point = best_split_point\n",
    "        root.childs = childs\n",
    "        if cnt == 0:\n",
    "            self.root = root\n",
    "        return root\n",
    "    \n",
    "    def predict(self, dataset):\n",
    "        result = []\n",
    "        for i in dataset.index:\n",
    "            cur_node = self.root\n",
    "            while cur_node.result is None:\n",
    "                value = dataset.loc[i, cur_node.split_feature]\n",
    "                if value < cur_node.split_point:\n",
    "                    cur_node = cur_node.childs[0]\n",
    "                else :\n",
    "                    cur_node = cur_node.childs[1]\n",
    "            result.append(cur_node.result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.DecisionTree object at 0x00000205D3827A88>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Node at 0x205d3827a48>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDT = DecisionTree()\n",
    "print(newDT)\n",
    "\n",
    "newDT.fit(test_X.head(100), test_Y.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Level  0  ::  SKEW_YEO_JONSON 0.6287600117852042 None\n",
      "  Level  1  ::  MIN_ONSET 0.918701171875 None\n",
      "   Level  2  ::  None None time pressure\n",
      "   Level  2  ::  SKEW -1.571927617886033e-16 None\n",
      "    Level  3  ::  None None interruption\n",
      "    Level  3  ::  SKEW 1.3895592427316656 None\n",
      "     Level  4  ::  None None no stress\n",
      "     Level  4  ::  ALSC 39.5004326609572 None\n",
      "      Level  5  ::  None None no stress\n",
      "      Level  5  ::  None None interruption\n",
      "  Level  1  ::  RANGE_BOXCOX -2.626687010094331 None\n",
      "   Level  2  ::  KURT 9.023855762998295 None\n",
      "    Level  3  ::  INSC_APSC 9526.51035036534 None\n",
      "     Level  4  ::  MEAN_1ST_GRAD -0.000255648014997318 None\n",
      "      Level  5  ::  STD_PEAKS 5.477192644234585 None\n",
      "       Level  6  ::  None None interruption\n",
      "       Level  6  ::  None None no stress\n",
      "      Level  5  ::  MAX_PEAKS 82.405029296875 None\n",
      "       Level  6  ::  MIN_PEAKS 2.716064453125 None\n",
      "        Level  7  ::  None None interruption\n",
      "        Level  7  ::  None None no stress\n",
      "       Level  6  ::  STD_PEAKS 32.428019466882 None\n",
      "        Level  7  ::  None None no stress\n",
      "        Level  7  ::  MIN_PEAKS 1.346923828125 None\n",
      "         Level  8  ::  None None no stress\n",
      "         Level  8  ::  None None interruption\n",
      "     Level  4  ::  MEAN_2ND_GRAD 5.645461832358632e-06 None\n",
      "      Level  5  ::  INSC_APSC 12359.48520462145 None\n",
      "       Level  6  ::  None None no stress\n",
      "       Level  6  ::  APSC_BOXCOX -978.8043995251605 None\n",
      "        Level  7  ::  None None time pressure\n",
      "        Level  7  ::  None None interruption\n",
      "      Level  5  ::  KURT 0.8166311872445741 None\n",
      "       Level  6  ::  MEAN 0.002673126783696221 None\n",
      "        Level  7  ::  None None interruption\n",
      "        Level  7  ::  None None no stress\n",
      "       Level  6  ::  None None no stress\n",
      "    Level  3  ::  None None no stress\n",
      "   Level  2  ::  MEAN_2ND_GRAD -0.0001209419307125705 None\n",
      "    Level  3  ::  KURT 3.7693371456809857 None\n",
      "     Level  4  ::  MEAN 0.11063649658894774 None\n",
      "      Level  5  ::  None None interruption\n",
      "      Level  5  ::  None None time pressure\n",
      "     Level  4  ::  None None no stress\n",
      "    Level  3  ::  RANGE 0.005636783991135964 None\n",
      "     Level  4  ::  None None interruption\n",
      "     Level  4  ::  None None time pressure\n"
     ]
    }
   ],
   "source": [
    "newDT.DT_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no stress',\n",
       " 'no stress',\n",
       " 'no stress',\n",
       " 'no stress',\n",
       " 'no stress',\n",
       " 'no stress',\n",
       " 'no stress',\n",
       " 'no stress',\n",
       " 'no stress',\n",
       " 'interruption',\n",
       " 'interruption']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = test_X.loc[0:10]\n",
    "newDT.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       no stress\n",
       "1       no stress\n",
       "2       no stress\n",
       "3       no stress\n",
       "4       no stress\n",
       "5       no stress\n",
       "6       no stress\n",
       "7       no stress\n",
       "8       no stress\n",
       "9    interruption\n",
       "Name: condition, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
